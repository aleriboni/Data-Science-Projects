{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 381 ms, sys: 161 ms, total: 542 ms\n",
      "Wall time: 860 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.progettoDM # Get the \"twitter\" database\n",
    "trenitalia = db.trenitalia # Get the \"tweets\" collection from the \"twitter\" database\n",
    "\n",
    "#staz = pd.read_csv(\"stazioni_final.csv\", sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione campo numero_fermate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creazione numero_fermate\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "            {\"$project\":\n",
    "                {\n",
    "                    \"numero_fermate\": { \"$cond\": { \"if\": { \"$isArray\": \"$fermate\" },\n",
    "                                                  \"then\": { \"$size\": \"$fermate\" }, \"else\": \"NA\"} }\n",
    "                }}\n",
    "        ]\n",
    "lista = list(db.trenitalia.aggregate(pipeline))\n",
    "\n",
    "\n",
    "for i in lista:\n",
    "    idx = i[\"_id\"]\n",
    "    numero_fermate = i[\"numero_fermate\"]\n",
    "    db.trenitalia.find_one_and_update({\"_id\": idx}, \n",
    "                                 {\"$set\": {\"numero_fermate\": numero_fermate}})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creazione durata teorica\n",
    "\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "        {\"$match\": {\"$or\":[{\"numero_fermate\": {\"$ne\":\"NA\"}}, {\"numero_fermate\": {\"$gt\":0}}]}},\n",
    "        {\"$project\": \n",
    "          {\n",
    "             \"partenza\": { \"$arrayElemAt\": [ \"$fermate\", 0 ] },\n",
    "             \"arrivo\": { \"$arrayElemAt\": [ \"$fermate\", -1 ] }\n",
    "          }\n",
    "        },\n",
    "        #{\"$convert\": { 'input': '$dateDifference', 'to': 'int' }}\n",
    "        #{\"$project\": {\"durata\": { \"$toInt\": \"$dateDifference\"}}}\n",
    "        #{\"$project\": {\"durata\": {\"$divide\": [ \"$durata\", 60000 ] }}}\n",
    "        {\"$group\": {\"_id\": {\"partenza\":\"$partenza.regione\",\"arrivo\":\"$arrivo.regione\"},\n",
    "                    \"somma\": {\"$sum\": 1}}}, \n",
    "          #          \"numero_treni\": {\"$sum\":1}}},\n",
    "         #{\"$sort\": SON([(\"media_ritardo\", -1), (\"_id\", -1)])}\n",
    "        ]\n",
    "lista = list(db.trenitalia.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/alessandro/Desktop/traffico_treni.json', 'w') as fout:\n",
    "    json.dump(lista , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None, 'count': 8583}]\n"
     ]
    }
   ],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "start = datetime(2019, 1, 30, 0, 0, 0)\n",
    "pipeline = [\n",
    "        {\"$match\": {\"categoria\":\"ES*\"}},\n",
    "        #{\"$project\": {\"_id\":1}},\n",
    "         {\"$group\": {\"_id\": \"$null\",\"count\": {\"$sum\": 1}}},\n",
    "         #{\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "]\n",
    "pprint.pprint(list(db.trenitalia.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "        {\"$unwind\":\"$fermate\"},\n",
    "         {\"$match\": { \"fermate.tipo_fermata\": \"A\"}},\n",
    "        {\"$match\":{\"$expr\": {\"$ne\": [\"$fermate.ritardo\", \"$ritardo_finale\"]}}},\n",
    "         #{\"$project\": {\"_id\":1,\"fermate.ritardo\":1}},\n",
    "        #{\"$group\": {\"_id\": \"null\", \"count\": {\"$sum\": 1}}},\n",
    "         #{\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "        ]\n",
    "pprint.pprint(list(db.trenitalia.aggregate(pipeline)))\n",
    "#\"$match\":{\"$expr\": {\"$eq\": [\"$a\", \"$b\"]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "        {\"$unwind\":\"$fermate\"},\n",
    "        #{\"$match\": { \"fermate.tipo_fermata\": \"A\"}},\n",
    "         #{\"$match\": { \"codice_treno\": \"REG5735\",\"stato\":\"parzialmente soppresso\"}},\n",
    "        #{\"$match\":{\"$expr\": {\"$ne\": [\"$fermate.ritardo\", \"$ritardo_finale\"]}}},\n",
    "         #{\"$project\": {\"_id\":1,\"fermate.ritardo\":1}},\n",
    "        {\"$group\": {\"_id\": \"$fermate.provincia\", \"count\": {\"$sum\": 1}, \"avg\": {\"$avg\":\"$fermate.ritardo\"}, \"index\": {\"$sum\":1}}},\n",
    "         {\"$sort\": SON([(\"count\", -1), (\"avg\", -1)])},\n",
    "        ]\n",
    "lista2 = (list(db.trenitalia.aggregate(pipeline)))\n",
    "for i in range(0,len(lista2)):\n",
    "    if lista2[i][\"avg\"] is not None:\n",
    "        lista2[i][\"index\"] = (lista2[i][\"avg\"] / lista2[i][\"count\"])*10000\n",
    "with open('index.json', 'w') as fout:\n",
    "    json.dump(lista2 , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j in range(0,len(lista2)):\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "         {\"$match\": {\"_id\":__id}},\n",
    "         {\"$project\": {\"_id\":1,\"fermate.ritardo\":1}},\n",
    "        {\"$group\": {\"_id\": \"null\", \"count\": {\"$sum\": 1}}},\n",
    "         {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "        ]\n",
    "pprint.pprint(list(db.trenitalia.aggregate(pipeline)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "         {\"$unwind\":\"$fermate\"},\n",
    "         #{\"$match\": { \"categoria\":\"ES*\"}},\n",
    "         #{\"$project\": {\"_id\":1,\"codice_treno\":1,\"data\":1,\"fermate.ritardo\":1}},\n",
    "         {\"$group\": {\"_id\":{\"_id\": \"$_id\",\"regione\": \"$fermate.regione\"}}},\n",
    "         {\"$group\": {\"_id\":\"$_id.regione\", \"count\": {\"$sum\": 1}}},\n",
    "        #{\"$project\": {\"codice_treno\":1,\"fermate.ritardo\":1}},\n",
    "         {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "        ]\n",
    "#pprint.pprint(list(db.trenitalia.aggregate(pipeline)))\n",
    "with open('treni_regione.json', 'w') as fout:\n",
    "    json.dump(list(db.trenitalia.aggregate(pipeline)) , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "        {\"$unwind\": \"$fermate\"},\n",
    "        {\"$match\": {\"categoria\":\"ES*\"}},\n",
    "        #{\"$project\": {\"_id\":-1,\"fermate.orario\":1,\"fermate.ritardo\":1,\n",
    "         #             \"fermate.regione\":1,\"categoria\":1}},\n",
    "        #{\"$group\": {\"_id\": \"$fermate.nome_stazione\", \"count_es\": {\"$sum\": 1}}},\n",
    "        #{\"$sort\": SON([(\"count_es\", -1), (\"_id\", -1)])}\n",
    "        ]\n",
    "#pprint.pprint(list(db.trenitalia.aggregate(pipeline)))\n",
    "\n",
    "lista = (list(db.trenitalia.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "        {\"$unwind\": \"$fermate\"},\n",
    "        #{\"$match\": {\"fermate.tipo_fermata\": \"P\"}},\n",
    "        #{\"$project\": {\"_id\":1}},\n",
    "         {\"$group\": {\"_id\": \"$fermate.provincia\", \"sum\": {\"$avg\": \"$fermate.ritardo\"}}},\n",
    "         {\"$sort\": SON([(\"avg\", -1), (\"count\", -1)])},\n",
    "        #{\"$match\": {\"count\": {\"$gt\":10}}},\n",
    "        ]\n",
    "\n",
    "with open('ritardi_provincia.json', 'w') as fout:\n",
    "    json.dump(list(db.trenitalia.aggregate(pipeline)) , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "start1 = datetime(2019, 1, 7, 0, 0, 0)\n",
    "pipeline = [\n",
    "        {\"$unwind\": \"$fermate\"},\n",
    "        {\"$match\": {\"fermate.regione\":\"LOMBARDIA\",\"categoria\":\"REG\"}},\n",
    "        {\"$project\": {\"hour\": { \"$hour\": \"$fermate.orario\" }, \"fermate.regione\":1,\n",
    "                    \"fermate.ritardo\":1}},\n",
    "        {\"$match\": {\"hour\": 4}},\n",
    "        {\"$group\": {\"_id\": \"$fermate.ritardo\", \"count\": {\"$sum\": 1}}},\n",
    "        {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])},\n",
    "        \n",
    "]\n",
    "lista = pprint.pprint(list(db.trenitalia.aggregate(pipeline)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creazione dataset per la terza infografica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def median(data):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m = np.median(a)\n",
    "    return m\n",
    "\n",
    "start1 = datetime(2019, 1, 12, 0, 0, 0)\n",
    "start2 = datetime(2019, 1, 19, 0, 0, 0)\n",
    "start3 = datetime(2019, 1, 26, 0, 0, 0)\n",
    "#start4 = datetime(2019, 1, 31, 0, 0, 0)\n",
    "start5 = datetime(2019, 1, 5, 0, 0, 0)\n",
    "\n",
    "#df = pd.DataFrame(columns=[\"giorno\",\"regione\",\"categoria\",\"mediana\",\"ora\"])\n",
    "\n",
    "categoria = [\"REG\",\"ES*\",\"MET\",\"IC\",\"EC\",\"EN\"]\n",
    "\n",
    "regioni_italiane = [\n",
    "    'CALABRIA',\n",
    "    'LIGURIA',\n",
    "    'SICILIA',\n",
    "    'TRENTINO ALTO ADIGE',\n",
    "    'EMILIA ROMAGNA',\n",
    "    'UMBRIA',\n",
    "    'MARCHE',\n",
    "    'ABRUZZO',\n",
    "    'PIEMONTE',\n",
    "    'VENETO',\n",
    "    'FRIULI VENEZIA GIULIA',\n",
    "    'PUGLIA',\n",
    "    'TOSCANA',\n",
    "    'BASILICATA',\n",
    "    'CAMPANIA',\n",
    "    'ESTERO',\n",
    "    'SARDEGNA',\n",
    "    'MOLISE',\n",
    "    \"VALLE D'AOSTA\",\n",
    "    'LAZIO',\n",
    "    'LOMBARDIA'\n",
    "]\n",
    "\n",
    "    \n",
    "pipeline = [\n",
    "        {\"$unwind\": \"$fermate\"},\n",
    "        {\"$match\": {\"$or\":[{\"data\":start1}, {\"data\":start2}, {\"data\":start3}, \n",
    "                           {\"data\":start5}]}},\n",
    "        {\"$project\": {\"hour\": { \"$hour\": \"$fermate.orario\" }, \"fermate.regione\":1,\n",
    "                      \"categoria\":1,\"fermate.ritardo\":1}},\n",
    "        ]\n",
    "\n",
    "lista = (list(db.trenitalia.aggregate(pipeline)))\n",
    "\n",
    "for ora in range(0,24):\n",
    "    L = list()\n",
    "    for i in range(0,len(lista)):\n",
    "        if lista[i][\"hour\"] == ora:\n",
    "            L.append(lista[i])\n",
    "        #L = [x for x in L if x is not None]\n",
    "    \n",
    "    for cat in categoria:\n",
    "        L_cat = list()\n",
    "        for j in range(0,len(L)):\n",
    "            if L[j][\"categoria\"] == cat:\n",
    "                L_cat.append(L[j])\n",
    "                \n",
    "        for reg in regioni_italiane:\n",
    "            L2 = list()\n",
    "            for k in range(0,len(L_cat)):\n",
    "                if L_cat[k][\"fermate\"][\"regione\"] == reg:\n",
    "                    L2.append(L_cat[k][\"fermate\"][\"ritardo\"])\n",
    "            L2 = [x for x in L2 if x is not None]\n",
    "            #media, m_min, m_sup = mean_confidence_interval(L2, confidence=0.95)\n",
    "            mediana = median(L2)\n",
    "            df = df.append({'giorno': \"sabato\", \"regione\": reg, \"mediana\":mediana,\n",
    "                            \"ora\":ora,\"categoria\":cat}, ignore_index=True)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"infografica3.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "#start = datetime(2019, 1, 30, 0, 0, 0)\n",
    "pipeline = [\n",
    "        {\"$match\": {\"categoria\":\"ES*\"}},\n",
    "        #{\"$project\": {\"_id\":1}},\n",
    "         {\"$group\": {\"_id\":\"$codice_treno\", \"ritardo_medio\":{\"$avg\": \"$ritardo_finale\"},\n",
    "                     \"count\": {\"$sum\": 1}}},\n",
    "         {\"$sort\": SON([(\"ritardo_medio\", -1), (\"_id\", -1)])}\n",
    "]\n",
    "pprint.pprint(list(db.trenitalia.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "#start = datetime(2019, 1, 30, 0, 0, 0)\n",
    "pipeline = [\n",
    "            {\"$match\": {\"categoria\":\"ES*\",\"origine\":\"TORINO P.NUOVA\",\n",
    "                    \"destinazione\":\"VENEZIA SANTA LUCIA\"}},\n",
    "            #{\"$project\": {\"fermate.nome_stazione\":1,\"tratta\":1}},\n",
    "        {\"$group\": {\"_id\":\"$tratta\", \"count\": {\"$sum\":1}}}\n",
    "]\n",
    "lista = (list(db.trenitalia.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON\n",
    "import pprint\n",
    "pipeline = [\n",
    "        #{\"$unwind\": \"$fermate\"},\n",
    "        {\"$match\": {\"categoria\": \"ES*\"}},\n",
    "        {\"$match\": {\"$or\":[{ \"stato\": {\"$ne\":\"parzialmente soppresso\"}},\n",
    "                           { \"stato\": {\"$ne\":\"cancellato\"}}]}},\n",
    "        {\"$project\": {\"data\":0,\"fermate.orario\":0}}\n",
    "        ]\n",
    "lista = list(db.trenitalia.aggregate(pipeline))\n",
    "\n",
    "for j in lista:\n",
    "    j[\"_id\"] = str(j[\"_id\"])\n",
    "\n",
    "with open('av_def.json', 'w') as fout:\n",
    "    json.dump(lista , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "        {\"$unwind\": \"$fermate\"},\n",
    "        {\"$match\": {\"fermate.regione\":\"LOMBARDIA\"}},\n",
    "        {\"$group\": {\"_id\": \"$fermate.nome_stazione\", \n",
    "                    \"ritardo_medio\": {\"$avg\": \"$fermate.ritardo\"}}},\n",
    "        {\"$sort\": SON([(\"ritardo_medio\", -1)])}\n",
    "]\n",
    "pd.DataFrame(list(db.trenitalia.aggregate(pipeline))[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
